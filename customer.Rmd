```{r}
library(matlib)
library(visdat)
library(ggplot2)
library(glmnet)
library(rsample)
library(MASS)
```

**Reading CSV File**

```{r}
customer_shopping = read.csv("./customer_shopping_data_1695379411426.csv")
```


**Understanding dataset**
```{r}
head(customer_shopping)
```

```{r}
tail(customer_shopping)
```

```{r}
summary(customer_shopping)
```

```{r}
# Check for missing values in the entire data frame
missing_values <- is.na(customer_shopping)
# Summarize the number of missing values in each column
missing_count <- colSums(missing_values)
print(missing_count)

```

```{r}
unique_genders <- unique(customer_shopping$gender)
print(unique_genders)

unique_category <- unique(customer_shopping$category)
print(unique_category)

unique_payment_method <- unique(customer_shopping$payment_method)
print(unique_payment_method)

unique_shopping_mall <- unique(customer_shopping$shopping_mall)
print(unique_shopping_mall)
```

```{r}
# Convert gender to numerical values
customer_shopping$gender <- as.numeric(factor(customer_shopping$gender, levels = unique(customer_shopping$gender)))

# Convert category to numerical values
customer_shopping$category <- as.numeric(factor(customer_shopping$category, levels = unique(customer_shopping$category)))

# Convert payment_method to numerical values
customer_shopping$payment_method <- as.numeric(factor(customer_shopping$payment_method, levels = unique(customer_shopping$payment_method)))

# Convert payment_method to numerical values
customer_shopping$shopping_mall <- as.numeric(factor(customer_shopping$shopping_mall, levels = unique(customer_shopping$shopping_mall)))

head(customer_shopping)

```

```{r}
# define input
x <- customer_shopping[, !(names(customer_shopping) %in% c("invoice_no","customer_id","quantity", "invoice_date", "gender", "shopping_mall"))]
```

```{r}
# Convert invoice_date to Date format if not already done
customer_shopping$invoice_date <- as.Date(customer_shopping$invoice_date, format="%d/%m/%Y")

# Create a time series object with monthly frequency (assuming data is monthly)
customer_shopping.ts <- ts(x, 
                            start = c(as.numeric(format(min(customer_shopping$invoice_date), "%Y")), 
                                      as.numeric(format(min(customer_shopping$invoice_date), "%m"))), 
                            end = c(as.numeric(format(max(customer_shopping$invoice_date), "%Y")), 
                                    as.numeric(format(max(customer_shopping$invoice_date), "%m"))), 
                            frequency = 12)  # Monthly data, so frequency is 12

# Plot the time series of input x with one-month interval
plot(customer_shopping.ts, main = "Time series plot of Input", 
     xlab = "Invoice Date", ylab = "X (inputs)")


```
**Old normal timeseries**
```{r}
#customer_shopping$invoice_date <- as.Date(customer_shopping$invoice_date, format="%d/%m/%Y")

# Create a time series object
#customer_shopping.ts <- ts(x, 
                            #start = c(min(customer_shopping$invoice_date)), 
                            #end = c(max(customer_shopping$invoice_date)), 
                            #frequency = 1)

# Plot the time series of input x
#plot(customer_shopping.ts, main = "Time series plot of Input", 
     #xlab = "Invoice Date", ylab = "X (inputs)")
```


```{r}

# Plot the time series of output y
# Convert invoice_date to Date format if not already done
customer_shopping$invoice_date <- as.Date(customer_shopping$invoice_date, format="%d/%m/%Y")
unique_dates <- unique(format(customer_shopping$invoice_date, "%Y-%m"))
# Create a time series object with monthly frequency (assuming data is monthly)
customer_shopping.ts <- ts(customer_shopping$quantity, 
                            start = c(as.numeric(format(min(customer_shopping$invoice_date), "%Y")), 
                                      as.numeric(format(min(customer_shopping$invoice_date), "%m"))), 
                            end = c(as.numeric(format(max(customer_shopping$invoice_date), "%Y")), 
                                    as.numeric(format(max(customer_shopping$invoice_date), "%m"))), 
                            frequency = 12)  # Monthly data, so frequency is 12
 
plot(customer_shopping.ts, main = "Time series plot of Output", 
     xlab = "Invoice Date", ylab = "Y (output) or Total Quantity")

```

**Distribution**
```{r}
dis=density(x$price)
plot(dis,main = "Density plot of price")

# Creating a Histogram of X Inputs
hist(x$price,freq = FALSE,main="Histogram and density plot of price",xlab = "Price")

#Adding density in the histogram
lines(dis,lwd=2,col="black")
rug(jitter(x$price))
```
```{r}
dis=density(x$payment_method)
plot(dis,main = "Density plot of whole inputs")

# Creating a Histogram of X Inputs
hist(x$payment_method,freq = FALSE,main="Histogram and density plot of payment Method",xlab = "Payment Method")

#Adding density in the histogram
lines(dis,lwd=2,col="black")
rug(jitter(x$payment_method))
```

```{r}
dis=density(x$age)
plot(dis,main = "Density plot of whole inputs")

# Creating a Histogram of X Inputs
hist(x$age,freq = FALSE,main = "Histogram and density plot of age")

#Adding density in the histogram
lines(dis,lwd=2,col="black")
rug(jitter(x$age))
```

```{r}
dis=density(x$category)
plot(dis,main = "Density plot of whole inputs")

# Creating a Histogram of X Inputs
hist(x$category,freq = FALSE,main = "Histogram and density plot of category")

#Adding density in the histogram
lines(dis,lwd=2,col="black")
rug(jitter(x$category))
```
```{r}
dis=density(customer_shopping$quantity)
plot(dis,main = "Density plot of whole inputs")

# Creating a Histogram of X Inputs
hist(customer_shopping$quantity,freq = FALSE,main = "Histogram and density plot of Quantity")

#Adding density in the histogram
lines(dis,lwd=2,col="black")
rug(jitter(x$customer_shopping$quantity))
```

```{r}
# Plotting age against quantity
Y <- customer_shopping$quantity
plot(x$age,Y,main = "Correlation betweeen age and quantity signal", xlab = "age", ylab = "quantity" )

plot(x$price,Y,main = "Correlation betweeen price and quantity signal", xlab = "price", ylab = "quantity" )

plot(x$category,Y,main = "Correlation betweeen category and quantity signal", xlab = "category", ylab = "quantity" )

plot(x$payment_method,Y,main = "Correlation betweeen payment_method and quantity signal", xlab = "payment_method", ylab = "quantity" )
```
```{r}
x$quantity <- customer_shopping$quantity
cor(x)
plot(x)
```

**Task 2**
```{r}
x$X1 <- x$age
x$X2 <- x$category
x$X3 <- x$price
x$X4 <- x$payment_method

x <- x[, c("X1", "X2", "X3", "X4")]
x <- as.matrix(x)
y <- as.matrix(customer_shopping$quantity)

ones <- matrix(1, length(x)/4,1)
```

**Task 1.1

```{r}

# Fit a ridge regression model
alpha <- 0  # 0 for ridge regression
lambda <- 1  # Adjust the lambda value as needed

# calculating theta of the model1
Y1 <- cbind(ones,(x[,"X4"]),(x[,"X1"])^2,(x[,"X1"])^3,(x[,"X2"])^4,(x[,"X1"])^4)
ridge_model1 <- glmnet(Y1, y, alpha = alpha, lambda = lambda)
thetaHatModel1 = coefficients(ridge_model1)
print(thetaHatModel1)

Y2 <- cbind(ones,(x[,"X4"]),(x[,"X1"])^3,(x[,"X3"])^4)
ridge_model2 <- glmnet(Y2, y, alpha = alpha, lambda = lambda)
thetaHatModel2 = coefficients(ridge_model2)
print(thetaHatModel2)

Y3 <- cbind(ones,(x[,"X3"])^3,(x[,"X3"])^4)
ridge_model3 <- glmnet(Y3, y, alpha = alpha, lambda = lambda)
thetaHatModel3 = coefficients(ridge_model3)
print(thetaHatModel3)

Y4 <- cbind(ones,(x[,"X2"]),(x[,"X1"])^3,(x[,"X3"])^4)
ridge_model4 <- glmnet(Y4, y, alpha = alpha, lambda = lambda)
thetaHatModel4 = coefficients(ridge_model4)
print(thetaHatModel4)

Y5 <- cbind(ones,(x[,"X4"]),(x[,"X1"])^2,(x[,"X1"])^3, (x[,"X3"]^4))
ridge_model5 <- glmnet(Y5, y, alpha = alpha, lambda = lambda)
thetaHatModel5 = coefficients(ridge_model5)
print(thetaHatModel5)

```

```{r}
# Calculate predicted values for the ridge regression model
Y_hat_ridge1 <- predict(ridge_model1, s = lambda, newx = Y1)
# Calculate residuals
residuals_ridge <- y - Y_hat_ridge1
# Calculate RSS for the ridge regression model
RSS_ridge <- sum(residuals_ridge^2)
# Extract coefficients for the specified lambda
coefficients_ridge <- coef(ridge_model1, s =lambda)
# Map coefficients to the corresponding columns of model1
Y_hat_m1 <- as.matrix(Y1) %*% coefficients_ridge[-1]  # Exclude the intercept term
# Calculate RSS for Model 1
residuals_m1 <- y - Y_hat_m1
RSS_Model_1 <- sum(residuals_m1^2)
print(RSS_Model_1)


#model2
Y_hat_ridge2 <- predict(ridge_model2, s = lambda, newx = Y2)
residuals_ridge <- y - Y_hat_ridge2
RSS_ridge <- sum(residuals_ridge^2)
coefficients_ridge <- coef(ridge_model2, s =lambda)
Y_hat_m2 <- as.matrix(Y2) %*% coefficients_ridge[-1]  
residuals_m2 <- y - Y_hat_m2
RSS_Model_2 <- sum(residuals_m2^2)
print(RSS_Model_2)

#model3
Y_hat_ridge3 <- predict(ridge_model3, s = lambda, newx = Y3)
residuals_ridge <- y - Y_hat_ridge3
RSS_ridge <- sum(residuals_ridge^2)
coefficients_ridge <- coef(ridge_model3, s =lambda)
Y_hat_m3 <- as.matrix(Y3) %*% coefficients_ridge[-1]  
residuals_m3 <- y - Y_hat_m3
RSS_Model_3 <- sum(residuals_m3^2)
print(RSS_Model_3)

#model4
Y_hat_ridge4 <- predict(ridge_model4, s = lambda, newx = Y4)
residuals_ridge <- y - Y_hat_ridge4
RSS_ridge <- sum(residuals_ridge^2)
coefficients_ridge <- coef(ridge_model4, s =lambda)
Y_hat_m4 <- as.matrix(Y4) %*% coefficients_ridge[-1]  
residuals_m4 <- y - Y_hat_m4
RSS_Model_4 <- sum(residuals_m4^2)
print(RSS_Model_4)

#model5
Y_hat_ridge5 <- predict(ridge_model5, s = lambda, newx = Y5)
residuals_ridge <- y - Y_hat_ridge5
RSS_ridge <- sum(residuals_ridge^2)
coefficients_ridge <- coef(ridge_model5, s =lambda)
Y_hat_m5 <- as.matrix(Y5) %*% coefficients_ridge[-1]  
residuals_m5 <- y - Y_hat_m5
RSS_Model_5 <- sum(residuals_m5^2)
print(RSS_Model_5)
```


```{r}
N=length(y)
#Calculating the Variance of Model 1
Variance_model1=RSS_Model_1/(N-1)
Variance_model1
#Calculating the log-likelihood of Model 1
likehood_Model_1 = -(N/2)*(log(2*pi))-(N/2)*(log(Variance_model1))-(1/(2*Variance_model1))*RSS_Model_1
likehood_Model_1


Variance_model2=RSS_Model_2/(N-1)
Variance_model2
#Calculating the log-likelihood of Model 1
likehood_Model_2 = -(N/2)*(log(2*pi))-(N/2)*(log(Variance_model2))-(1/(2*Variance_model2))*RSS_Model_2
likehood_Model_2

Variance_model3=RSS_Model_3/(N-1)
Variance_model3
#Calculating the log-likelihood of Model 1
likehood_Model_3 = -(N/2)*(log(2*pi))-(N/2)*(log(Variance_model3))-(1/(2*Variance_model3))*RSS_Model_3
likehood_Model_3

Variance_model4=RSS_Model_2/(N-1)
Variance_model4
#Calculating the log-likelihood of Model 1
likehood_Model_4 = -(N/2)*(log(2*pi))-(N/2)*(log(Variance_model4))-(1/(2*Variance_model4))*RSS_Model_4
likehood_Model_4

Variance_model5=RSS_Model_5/(N-1)
Variance_model5
#Calculating the log-likelihood of Model 1
likehood_Model_5 = -(N/2)*(log(2*pi))-(N/2)*(log(Variance_model5))-(1/(2*Variance_model5))*RSS_Model_5
likehood_Model_5
```
```{r}
##Calculating AIC and BIC of model 1
K_model1<-length(thetaHatModel1)
K_model1
AIC_model1=2*K_model1-2*likehood_Model_1
AIC_model1
BIC_model1=K_model1*log(N)-2*likehood_Model_1
BIC_model1


K_model2<-length(thetaHatModel2)
K_model2
AIC_model2=2*K_model2-2*likehood_Model_2
AIC_model2
BIC_model2=K_model2*log(N)-2*likehood_Model_2
BIC_model2

K_model3<-length(thetaHatModel3)
K_model3
AIC_model3=2*K_model3-2*likehood_Model_3
AIC_model3
BIC_model3=K_model3*log(N)-2*likehood_Model_3
BIC_model3

K_model4<-length(thetaHatModel4)
K_model4
AIC_model4=2*K_model4-2*likehood_Model_4
AIC_model4
BIC_model4=K_model4*log(N)-2*likehood_Model_4
BIC_model4


K_model5<-length(thetaHatModel5)
K_model5
AIC_model5=2*K_model5-2*likehood_Model_5
AIC_model5
BIC_model5=K_model5*log(N)-2*likehood_Model_5
BIC_model5
```
```{r}
## Error of model1
model1_error <- y-Y_hat_m1
## Plotting the graph QQplot and QQ line of model 1
qqnorm(model1_error, col = "darkcyan",main = "QQ plot of model 1")
qqline(model1_error, col = "red",lwd=1)

model2_error <- y-Y_hat_m2
## Plotting the graph QQplot and QQ line of model 1
qqnorm(model2_error, col = "darkcyan",main = "QQ plot of model 2")
qqline(model2_error, col = "red",lwd=1)

model3_error <- y-Y_hat_m3
## Plotting the graph QQplot and QQ line of model 1
qqnorm(model3_error, col = "darkcyan",main = "QQ plot of model 3")
qqline(model3_error, col = "red",lwd=1)

model4_error <- y-Y_hat_m4
## Plotting the graph QQplot and QQ line of model 1
qqnorm(model4_error, col = "darkcyan",main = "QQ plot of model 4")
qqline(model4_error, col = "red",lwd=1)

model5_error <- y-Y_hat_m5
## Plotting the graph QQplot and QQ line of model 1
qqnorm(model5_error, col = "darkcyan",main = "QQ plot of model 5")
qqline(model5_error, col = "red",lwd=1)
```
```{r}
# Split the data into training and testing sets (70% training, 30% testing)
set.seed(123)  # Set seed for reproducibility
split_X <- initial_split(data = as.data.frame(x), prop = 0.7)
split_Y <- initial_split(data = as.data.frame(y), prop = 0.7)

X_training_set <- training(split_X)
X_testing_set <- testing(split_X)
Y_training_set <- as.matrix(training(split_Y))
Y_testing_set <- as.matrix(testing(split_Y))

# Create the design matrix for the selected 'best' model
traning_ones <- matrix(1, nrow = nrow(X_training_set), ncol = 1)
X_training_model <- cbind(traning_ones, X_training_set[,"X2"], (X_training_set[,"X1"])^3, (X_training_set[,"X3"])^4)

# Estimate model parameters using training data
theta_hat <- ginv(t(X_training_model) %*% X_training_model) %*% t(X_training_model) %*% Y_training_set

# Create the design matrix for the testing data using the same model equation
traning_ones_test <- matrix(1, nrow = nrow(X_testing_set), ncol = 1)
X_testing_model <- cbind(traning_ones_test, X_testing_set[,"X2"], (X_testing_set[,"X1"])^3, (X_testing_set[,"X3"])^4)

# Compute model predictions on the testing data
Y_testing_hat <- X_testing_model %*% theta_hat

# Calculate 95% confidence intervals for the model predictions
z <- qnorm(0.975)  # Z-score for 95% confidence interval
n_len <- nrow(X_testing_model)
error <- Y_testing_set - Y_testing_hat
valid_indices <- (error != 0)  # Check for non-zero error values

# Ensure that the values inside sqrt are non-negative using abs function
C_I_1 <- ifelse(valid_indices, z * sqrt(abs(error * (1 - error)) / n_len), 0)
C_I_2 <- ifelse(valid_indices, z * sqrt(abs(error * (1 + error)) / n_len), 0)


# Plotting
plot(Y_testing_set, col = "red", pch = 19, xlab = "Index", ylab = "Y Value", main = "Model Predictions and 95% Confidence Intervals")
points(Y_testing_hat, col = "blue", pch = 19)

# Add error bars for 95% confidence intervals
arrows(x0 = 1:n_len, y0 = Y_testing_hat - C_I_1, y1 = Y_testing_hat + C_I_2, angle = 90, code = 3, length = 0.1, col = "green")

# Legend
legend("topright", legend = c("Testing Data", "Model Predictions", "95% CI"), col = c("red", "blue", "green"), pch = 19, cex = 0.8)


```

```{r}
## Model 2 will be used, parameter are selected and kept constant.
arr_1=0
arr_2=0
f_value=0
s_value=0
thetaHatModel2
#values from thetahat
thetebias <- 0.483065688 #selected parameter
thetaone <-0.143578928 # selected parameter
thetatwo <- 0.010038614 # constant value
thetathree <- 0.001912836 # constant value


Epison <- RSS_Model_2 * 2 ## fixing value of eplision
num <- 100 #number of iteration
##Calculating Y-hat for performing rejection ABC
counter <- 0
for (i in 1:num) {
  range1 <- runif(1,-0.483065688,0.483065688) # calculating the range
  range1
  range2 <- runif(1,-0.143578928,0.143578928)
  New_thetahat <- matrix(c(range1,range2,thetatwo,thetathree))
  New_Y_Hat <- Y2 %*% New_thetahat ## calculating new Y-hat
  new_RSS <- sum((y-New_Y_Hat)^2)
  new_RSS
  if (new_RSS > Epison){
    arr_1[i] <- range1
    arr_2[i] <- range2
    counter = counter+1
    f_value <- matrix(arr_1)
    s_value <- matrix(arr_2)
  }
}
hist(f_value)
hist(s_value)

###ploting Joint and Marginal Posterior Distribution of the graph
plot(f_value,s_value, col = c("brown", "blue"), main = "Joint and Marginal Posterior Distribution")
par(mfrow=c(1,1))
```


